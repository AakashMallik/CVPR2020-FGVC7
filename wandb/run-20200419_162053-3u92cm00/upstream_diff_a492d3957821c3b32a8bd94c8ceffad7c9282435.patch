diff --git a/.vscode/settings.json b/.vscode/settings.json
index a2a69c0..34b0917 100644
--- a/.vscode/settings.json
+++ b/.vscode/settings.json
@@ -5,12 +5,14 @@
     "cSpell.words": [
         "get",
         "header",
+        "init",
         "kaggle",
         "optimier",
         "optimiser",
         "optimisers",
         "output",
         "tqdm",
-        "trange"
+        "trange",
+        "wandb"
     ]
 }
\ No newline at end of file
diff --git a/README.md b/README.md
index 6786dde..416433d 100644
--- a/README.md
+++ b/README.md
@@ -125,6 +125,7 @@ Sample files ( train_dummy_1, train_dummy_2 ) are provided in the examples direc
 
 ```
 mode: train
+seed: (optional)
 validation_frequency: ( optional )
 epochs:
 batch_size: ( optional )
@@ -139,7 +140,7 @@ val_dataset:
   resize_dims:
 model: 
   name:
-  pred_type: regression/classification
+  pred_type: regression/classification/mixed
   tuning_type: feature-extraction/fine-tuning
   hyper_params: ( depends on the model )
     key_1:  ( depends on the model )
@@ -157,8 +158,10 @@ scheduler:
     key_1: ( depends on the scheduler )
     key_2: ( depends on the scheduler )
 loss_function: 
-  name: 
-
+  name: ( in case of mixed, this will be the regression loss )
+  hyper_params:
+    classification_loss: ( in case of mixed )
+    classification_coefficient: ( in case of mixed - (0, 1) )
 ```
 
 ### Test
@@ -175,6 +178,7 @@ experiment_list:
   - experiment:
       path: ( valid train config file name )
       weight_type: ( optional key to pick the type of weight - best_val_loss/best_val_roc )
+      resize_dims: ( optional override - original/integer - Use the training config values or the integer passed )
   - experiment:
       path: ( valid train config file name )
       weight_type: ( optional key to pick the type of weight - best_val_loss/best_val_roc )
@@ -182,7 +186,7 @@ experiment_list:
 
 ## Lib dependency
 ```bash
-pip install --user torch torchvision catalyst albumentations pandas scikit-image tqdm scikit-learn pyyaml blessed pyzmq pretrainedmodels tensorboard
+pip install --user torch wandb torchvision catalyst albumentations pandas scikit-image tqdm scikit-learn pyyaml blessed pyzmq pretrainedmodels tensorboard
 ```
 
 ## Utility commands
diff --git a/main.py b/main.py
index e33dfd6..60c2d27 100644
--- a/main.py
+++ b/main.py
@@ -5,6 +5,7 @@ from auto_aug import search
 from utils.config_parser import get_config_data
 from utils.check_gpu import get_training_device
 from utils.seed_backend import seed_all
+from utils.wandb_update import wandb_init
 
 # Parse arguments
 parser = argparse.ArgumentParser()
@@ -33,6 +34,7 @@ elif config['mode'] == 'train':
     if args.auto_aug:
         search( config, device )
     else:
+        config['publish'] and wandb_init()
         train( config, device )
 else:
     print("[ Experiment Mode should either be train/test ]")
diff --git a/run.sh b/run.sh
index 921b986..7557bbb 100755
--- a/run.sh
+++ b/run.sh
@@ -54,4 +54,6 @@
 
 # python ./main.py "test_b4.yml"
 
-python ./main.py -a 'aug_search.yml'
\ No newline at end of file
+# python ./main.py -a 'aug_search.yml'
+
+python ./main.py -p 'b4_14.yml'
\ No newline at end of file
diff --git a/train.py b/train.py
index a3f178f..2c41db0 100644
--- a/train.py
+++ b/train.py
@@ -194,8 +194,11 @@ def train(config, device, policy=None):
                         model.state_dict()
                     )
 
-    # publish on telegram
-    config['publish'] and experiment_helper.publish()
+                # publish intermediate
+                config['publish'] and experiment_helper.publish_intermediate()
+
+    # publish final
+    config['publish'] and experiment_helper.publish(config)
 
     return (experiment_helper.best_val_loss, experiment_helper.best_val_roc)
 
diff --git a/utils/__pycache__/experiment_utils.cpython-37.pyc b/utils/__pycache__/experiment_utils.cpython-37.pyc
index 7c27bc4..a47fe33 100644
Binary files a/utils/__pycache__/experiment_utils.cpython-37.pyc and b/utils/__pycache__/experiment_utils.cpython-37.pyc differ
diff --git a/utils/experiment_utils.py b/utils/experiment_utils.py
index e42c4d8..ba17f1f 100644
--- a/utils/experiment_utils.py
+++ b/utils/experiment_utils.py
@@ -6,7 +6,8 @@ import math
 from utils.regression_utils import covert_to_classification
 from utils.kaggle_metric import (roc_auc_score_generator)
 from utils.print_util import cprint
-from utils.telegram_update import publish
+from utils.telegram_update import publish_msg
+from utils.wandb_update import (publish_intermediate, publish_final)
 
 
 def accuracy_generator(output_list, target_list):
@@ -43,6 +44,15 @@ class ExperimentHelper:
             "train_roc": None,
             "epoch": None
         }
+        self.intermediate_result = {
+            "val_loss": self.best_val_loss,
+            "val_acc": None,
+            "train_loss": None,
+            "train_acc": None,
+            "val_roc": None,
+            "train_roc": None,
+            "epoch": None
+        }
         self.tb_writer = tb_writer
         self.freq = freq
         self.progress_loss = False
@@ -121,6 +131,15 @@ class ExperimentHelper:
                 self.tb_writer.add_scalar('ROC/Train', train_roc, epoch)
                 self.tb_writer.add_scalar('ROC/Validation', val_roc, epoch)
 
+            # storing intermediate values for logging
+            self.intermediate_result["val_loss"] = val_loss
+            self.intermediate_result["val_acc"] = val_acc
+            self.intermediate_result["train_loss"] = train_loss
+            self.intermediate_result["train_acc"] = train_acc
+            self.intermediate_result["val_kaggle_metric"] = val_roc
+            self.intermediate_result["train_kaggle_metric"] = train_roc
+            self.intermediate_result["epoch"] = epoch
+
             # storing loss for check
             if self.best_val_loss >= val_loss:
                 self.best_val_loss = val_loss
@@ -131,8 +150,8 @@ class ExperimentHelper:
                 self.result["val_acc"] = val_acc
                 self.result["train_loss"] = train_loss
                 self.result["train_acc"] = train_acc
-                self.result["val_roc"] = val_roc
-                self.result["train_roc"] = train_roc
+                self.result["val_kaggle_metric"] = val_roc
+                self.result["train_kaggle_metric"] = train_roc
                 self.result["epoch"] = epoch
             else:
                 self.progress_loss = False
@@ -146,5 +165,12 @@ class ExperimentHelper:
 
             return (val_loss, train_loss, val_acc, train_acc, val_roc, train_roc)
 
-    def publish(self):
-        publish(self.result)
+    def publish(self, config):
+        # telegram
+        # publish_msg(self.result)
+        # wandb
+        publish_final(config)
+
+    def publish_intermediate(self):
+        # wandb
+        publish_intermediate(self.intermediate_result)
diff --git a/utils/telegram_update.py b/utils/telegram_update.py
index 6d00287..a0ad2b6 100644
--- a/utils/telegram_update.py
+++ b/utils/telegram_update.py
@@ -5,7 +5,7 @@ import socket
 from utils.print_util import cprint
 
 
-def publish(results):
+def publish_msg(results):
     ctx = zmq.Context()
     sock = ctx.socket(zmq.PUSH)
     sock.connect("tcp://192.168.100.21:1234")
